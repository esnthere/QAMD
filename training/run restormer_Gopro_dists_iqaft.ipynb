{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0.0\n",
      "lr: 1e-05\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\cuda\\nccl.py:16: UserWarning: PyTorch is not compiled with NCCL support\n",
      "warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "Train Epoch:0 \t Mean Loss: 0.0281 Loss1: 0.0121Loss2: 0.0091 Loss3_1: 0.0152  Loss3_2: 0.0076\n",
      "time: 256.30621361732483\n",
      "lr: 1e-05\n",
      "Train Epoch:1 \t Mean Loss: 0.0268 Loss1: 0.0120Loss2: 0.0090 Loss3_1: 0.0137  Loss3_2: 0.0068\n",
      "time: 243.9883005619049\n",
      "lr: 1e-05\n",
      "Train Epoch:2 \t Mean Loss: 0.0256 Loss1: 0.0120Loss2: 0.0080 Loss3_1: 0.0127  Loss3_2: 0.0064\n",
      "time: 501.98011088371277\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Test Epoch:2 \t Mean Loss4: 0.0284\n",
      "time: 2082.4042241573334\n",
      "lr: 1e-05\n",
      "Train Epoch:3 \t Mean Loss: 0.0248 Loss1: 0.0122Loss2: 0.0076 Loss3_1: 0.0118  Loss3_2: 0.0059\n",
      "time: 497.74426674842834\n",
      "lr: 1e-05\n",
      "Train Epoch:4 \t Mean Loss: 0.0244 Loss1: 0.0124Loss2: 0.0073 Loss3_1: 0.0111  Loss3_2: 0.0056\n",
      "time: 500.59498953819275\n",
      "Test Epoch:4 \t Mean Loss4: 0.0286\n",
      "time: 2083.3130202293396\n",
      "lr: 1e-05\n",
      "Train Epoch:5 \t Mean Loss: 0.0236 Loss1: 0.0121Loss2: 0.0073 Loss3_1: 0.0105  Loss3_2: 0.0053\n",
      "time: 498.38736391067505\n",
      "lr: 1e-05\n",
      "Train Epoch:6 \t Mean Loss: 0.0235 Loss1: 0.0124Loss2: 0.0072 Loss3_1: 0.0100  Loss3_2: 0.0050\n",
      "time: 500.03946590423584\n",
      "Test Epoch:6 \t Mean Loss4: 0.0281\n",
      "time: 2087.451496362686\n",
      "lr: 1e-05\n",
      "Train Epoch:7 \t Mean Loss: 0.0230 Loss1: 0.0122Loss2: 0.0072 Loss3_1: 0.0095  Loss3_2: 0.0048\n",
      "time: 498.0769200325012\n",
      "lr: 1e-05\n",
      "Train Epoch:8 \t Mean Loss: 0.0229 Loss1: 0.0125Loss2: 0.0072 Loss3_1: 0.0091  Loss3_2: 0.0046\n",
      "time: 501.0118086338043\n",
      "Test Epoch:8 \t Mean Loss4: 0.0276\n",
      "time: 2084.8358993530273\n",
      "lr: 1e-05\n",
      "Train Epoch:9 \t Mean Loss: 0.0221 Loss1: 0.0120Loss2: 0.0071 Loss3_1: 0.0088  Loss3_2: 0.0044\n",
      "time: 497.8203148841858\n",
      "lr: 1e-05\n",
      "Train Epoch:10 \t Mean Loss: 0.0220 Loss1: 0.0121Loss2: 0.0071 Loss3_1: 0.0085  Loss3_2: 0.0043\n",
      "time: 500.131639957428\n",
      "Test Epoch:10 \t Mean Loss4: 0.0281\n",
      "time: 2078.049576997757\n",
      "lr: 1e-05\n",
      "Train Epoch:11 \t Mean Loss: 0.0219 Loss1: 0.0120Loss2: 0.0072 Loss3_1: 0.0083  Loss3_2: 0.0042\n",
      "time: 498.4812753200531\n",
      "lr: 1e-05\n",
      "Train Epoch:12 \t Mean Loss: 0.0216 Loss1: 0.0120Loss2: 0.0070 Loss3_1: 0.0081  Loss3_2: 0.0041\n",
      "time: 500.23619174957275\n",
      "Test Epoch:12 \t Mean Loss4: 0.0285\n",
      "time: 2077.785998106003\n",
      "lr: 1e-05\n",
      "Train Epoch:13 \t Mean Loss: 0.0214 Loss1: 0.0120Loss2: 0.0069 Loss3_1: 0.0079  Loss3_2: 0.0040\n",
      "time: 497.1477258205414\n",
      "lr: 1e-05\n",
      "Train Epoch:14 \t Mean Loss: 0.0215 Loss1: 0.0123Loss2: 0.0068 Loss3_1: 0.0077  Loss3_2: 0.0039\n",
      "time: 499.56316781044006\n",
      "Test Epoch:14 \t Mean Loss4: 0.0283\n",
      "time: 2076.1043725013733\n",
      "lr: 3e-06\n",
      "Train Epoch:15 \t Mean Loss: 0.0226 Loss1: 0.0123Loss2: 0.0071 Loss3_1: 0.0089  Loss3_2: 0.0045\n",
      "time: 496.3362889289856\n",
      "lr: 3e-06\n",
      "Train Epoch:16 \t Mean Loss: 0.0224 Loss1: 0.0124Loss2: 0.0068 Loss3_1: 0.0088  Loss3_2: 0.0044\n",
      "time: 499.3831057548523\n",
      "Test Epoch:16 \t Mean Loss4: 0.0280\n",
      "time: 2070.9464342594147\n",
      "lr: 3e-06\n",
      "Train Epoch:17 \t Mean Loss: 0.0223 Loss1: 0.0122Loss2: 0.0071 Loss3_1: 0.0087  Loss3_2: 0.0044\n",
      "time: 496.6928741931915\n",
      "lr: 3e-06\n",
      "Train Epoch:18 \t Mean Loss: 0.0224 Loss1: 0.0123Loss2: 0.0073 Loss3_1: 0.0086  Loss3_2: 0.0044\n",
      "time: 498.37546730041504\n",
      "Test Epoch:18 \t Mean Loss4: 0.0282\n",
      "time: 2076.015405893326\n",
      "lr: 3e-06\n",
      "Train Epoch:19 \t Mean Loss: 0.0221 Loss1: 0.0122Loss2: 0.0070 Loss3_1: 0.0085  Loss3_2: 0.0043\n",
      "time: 497.2528073787689\n",
      "lr: 3e-06\n",
      "Train Epoch:20 \t Mean Loss: 0.0222 Loss1: 0.0123Loss2: 0.0070 Loss3_1: 0.0085  Loss3_2: 0.0043\n",
      "time: 499.4052379131317\n",
      "Test Epoch:20 \t Mean Loss4: 0.0282\n",
      "time: 2079.420368909836\n",
      "Train End! The best model:\n",
      "Test Epoch:20 \t Mean Loss4: 0.0276\n"
     ]
    }
   ],
   "source": [
    "run restormer_Gopro_dists_iqaft"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
