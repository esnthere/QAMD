{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0.0\n",
      "lr: 1e-05\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\cuda\\nccl.py:16: UserWarning: PyTorch is not compiled with NCCL support\n",
      "warnings.warn('PyTorch is not compiled with NCCL support')\n",
      "Train Epoch:0 \t Mean Loss: 0.0376 Loss1: 0.0197Loss2: 0.0147 Loss3_1: 0.0140  Loss3_2: 0.0070\n",
      "time: 460.95821022987366\n",
      "lr: 1e-05\n",
      "Train Epoch:1 \t Mean Loss: 0.0363 Loss1: 0.0199Loss2: 0.0146 Loss3_1: 0.0120  Loss3_2: 0.0061\n",
      "time: 448.1858260631561\n",
      "lr: 1e-05\n",
      "Train Epoch:2 \t Mean Loss: 0.0338 Loss1: 0.0198Loss2: 0.0114 Loss3_1: 0.0110  Loss3_2: 0.0055\n",
      "time: 912.6368663311005\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Test Epoch:2 \t Mean Loss4: 0.0513\n",
      "time: 1654.2551634311676\n",
      "lr: 1e-05\n",
      "Train Epoch:3 \t Mean Loss: 0.0330 Loss1: 0.0202Loss2: 0.0103 Loss3_1: 0.0101  Loss3_2: 0.0051\n",
      "time: 906.952130317688\n",
      "lr: 1e-05\n",
      "Train Epoch:4 \t Mean Loss: 0.0320 Loss1: 0.0199Loss2: 0.0101 Loss3_1: 0.0095  Loss3_2: 0.0048\n",
      "time: 911.587327003479\n",
      "Test Epoch:4 \t Mean Loss4: 0.0509\n",
      "time: 1653.7732615470886\n",
      "lr: 1e-05\n",
      "Train Epoch:5 \t Mean Loss: 0.0315 Loss1: 0.0197Loss2: 0.0101 Loss3_1: 0.0090  Loss3_2: 0.0046\n",
      "time: 907.5600016117096\n",
      "lr: 1e-05\n",
      "Train Epoch:6 \t Mean Loss: 0.0315 Loss1: 0.0201Loss2: 0.0098 Loss3_1: 0.0086  Loss3_2: 0.0044\n",
      "time: 911.3654954433441\n",
      "Test Epoch:6 \t Mean Loss4: 0.0518\n",
      "time: 1651.2075097560883\n",
      "lr: 1e-05\n",
      "Train Epoch:7 \t Mean Loss: 0.0311 Loss1: 0.0200Loss2: 0.0098 Loss3_1: 0.0083  Loss3_2: 0.0042\n",
      "time: 907.2220788002014\n",
      "lr: 1e-05\n",
      "Train Epoch:8 \t Mean Loss: 0.0307 Loss1: 0.0198Loss2: 0.0096 Loss3_1: 0.0081  Loss3_2: 0.0041\n",
      "time: 911.2188980579376\n",
      "Test Epoch:8 \t Mean Loss4: 0.0516\n",
      "time: 1652.628978252411\n",
      "lr: 1e-05\n",
      "Train Epoch:9 \t Mean Loss: 0.0303 Loss1: 0.0195Loss2: 0.0096 Loss3_1: 0.0079  Loss3_2: 0.0041\n",
      "time: 909.4718236923218\n",
      "lr: 1e-05\n",
      "Train Epoch:10 \t Mean Loss: 0.0302 Loss1: 0.0196Loss2: 0.0096 Loss3_1: 0.0077  Loss3_2: 0.0040\n",
      "time: 909.4775035381317\n",
      "Test Epoch:10 \t Mean Loss4: 0.0508\n",
      "time: 1655.891970872879\n",
      "lr: 1e-05\n",
      "Train Epoch:11 \t Mean Loss: 0.0298 Loss1: 0.0194Loss2: 0.0096 Loss3_1: 0.0075  Loss3_2: 0.0039\n",
      "time: 906.9488880634308\n",
      "lr: 1e-05\n",
      "Train Epoch:12 \t Mean Loss: 0.0297 Loss1: 0.0193Loss2: 0.0096 Loss3_1: 0.0073  Loss3_2: 0.0038\n",
      "time: 911.4693171977997\n",
      "Test Epoch:12 \t Mean Loss4: 0.0504\n",
      "time: 1653.5941429138184\n",
      "lr: 1e-05\n",
      "Train Epoch:13 \t Mean Loss: 0.0296 Loss1: 0.0194Loss2: 0.0095 Loss3_1: 0.0072  Loss3_2: 0.0037\n",
      "time: 906.2762825489044\n",
      "lr: 1e-05\n",
      "Train Epoch:14 \t Mean Loss: 0.0298 Loss1: 0.0197Loss2: 0.0095 Loss3_1: 0.0070  Loss3_2: 0.0037\n",
      "time: 912.6617076396942\n",
      "Test Epoch:14 \t Mean Loss4: 0.0500\n",
      "time: 1655.5068094730377\n",
      "lr: 1e-05\n",
      "Train Epoch:15 \t Mean Loss: 0.0296 Loss1: 0.0197Loss2: 0.0094 Loss3_1: 0.0069  Loss3_2: 0.0036\n",
      "time: 906.650128364563\n",
      "lr: 1e-05\n",
      "Train Epoch:16 \t Mean Loss: 0.0297 Loss1: 0.0198Loss2: 0.0094 Loss3_1: 0.0068  Loss3_2: 0.0036\n",
      "time: 909.70880651474\n",
      "Test Epoch:16 \t Mean Loss4: 0.0508\n",
      "time: 1652.961226940155\n",
      "lr: 1e-05\n",
      "Train Epoch:17 \t Mean Loss: 0.0293 Loss1: 0.0196Loss2: 0.0093 Loss3_1: 0.0067  Loss3_2: 0.0035\n",
      "time: 905.4811837673187\n",
      "lr: 1e-05\n",
      "Train Epoch:18 \t Mean Loss: 0.0290 Loss1: 0.0194Loss2: 0.0093 Loss3_1: 0.0066  Loss3_2: 0.0035\n",
      "time: 907.1628601551056\n",
      "Test Epoch:18 \t Mean Loss4: 0.0502\n",
      "time: 1649.8894851207733\n",
      "lr: 1e-05\n",
      "Train Epoch:19 \t Mean Loss: 0.0289 Loss1: 0.0192Loss2: 0.0093 Loss3_1: 0.0065  Loss3_2: 0.0035\n",
      "time: 905.8705179691315\n",
      "lr: 1e-05\n",
      "Train Epoch:20 \t Mean Loss: 0.0289 Loss1: 0.0194Loss2: 0.0092 Loss3_1: 0.0064  Loss3_2: 0.0034\n",
      "time: 908.2618591785431\n",
      "Test Epoch:20 \t Mean Loss4: 0.0501\n",
      "time: 1653.1196529865265\n",
      "lr: 3e-06\n",
      "Train Epoch:21 \t Mean Loss: 0.0291 Loss1: 0.0191Loss2: 0.0093 Loss3_1: 0.0069  Loss3_2: 0.0036\n",
      "time: 905.1127951145172\n",
      "lr: 3e-06\n",
      "Train Epoch:22 \t Mean Loss: 0.0293 Loss1: 0.0194Loss2: 0.0092 Loss3_1: 0.0069  Loss3_2: 0.0036\n",
      "time: 908.0919618606567\n",
      "Test Epoch:22 \t Mean Loss4: 0.0501\n",
      "time: 1650.5716483592987\n",
      "lr: 3e-06\n",
      "Train Epoch:23 \t Mean Loss: 0.0290 Loss1: 0.0193Loss2: 0.0090 Loss3_1: 0.0069  Loss3_2: 0.0036\n",
      "time: 908.3875229358673\n",
      "lr: 3e-06\n",
      "Train Epoch:24 \t Mean Loss: 0.0292 Loss1: 0.0194Loss2: 0.0093 Loss3_1: 0.0069  Loss3_2: 0.0036\n",
      "time: 909.3659031391144\n",
      "Test Epoch:24 \t Mean Loss4: 0.0511\n",
      "time: 1648.600089788437\n",
      "lr: 3e-06\n",
      "Train Epoch:25 \t Mean Loss: 0.0294 Loss1: 0.0195Loss2: 0.0093 Loss3_1: 0.0068  Loss3_2: 0.0036\n",
      "time: 919.7811708450317\n",
      "lr: 3e-06\n",
      "Train Epoch:26 \t Mean Loss: 0.0292 Loss1: 0.0194Loss2: 0.0093 Loss3_1: 0.0068  Loss3_2: 0.0035\n",
      "time: 931.8008451461792\n",
      "Test Epoch:26 \t Mean Loss4: 0.0504\n",
      "time: 1712.1984968185425\n",
      "Train End! The best model:\n",
      "Test Epoch:26 \t Mean Loss4: 0.0500\n"
     ]
    }
   ],
   "source": [
    "run restormer_RealJ_dists_iqaft"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
